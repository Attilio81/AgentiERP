# ╔══════════════════════════════════════════════════════════════════════════════╗
# ║                         DATAPIZZA AGENT - CONFIGURAZIONE                      ║
# ╠══════════════════════════════════════════════════════════════════════════════╣
# ║  Copia questo file in .env e modifica i valori secondo le tue esigenze       ║
# ║  Per Docker: usa questo file nella root del progetto                          ║
# ║  Per sviluppo locale: copia anche in backend/.env                             ║
# ╚══════════════════════════════════════════════════════════════════════════════╝


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                              1. DATABASE                                      │
# └──────────────────────────────────────────────────────────────────────────────┘
# Connection string SQL Server
# Per Docker: usa host.docker.internal per raggiungere il DB sul tuo PC
DATABASE_URL=mssql+pyodbc://user:password@host.docker.internal:1433/EGM_AI?driver=ODBC+Driver+18+for+SQL+Server


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                     2. AGENT PRINCIPALE (Query SQL)                           │
# └──────────────────────────────────────────────────────────────────────────────┘
# Provider per l'agent che esegue query SQL e analisi dati
# Opzioni: anthropic | openai | gemini | lmstudio
LLM_PROVIDER=anthropic

# Modello per l'agent (dipende dal provider scelto)
# Anthropic: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022
# OpenAI: gpt-4o, gpt-4-turbo
# LM Studio: nome del modello caricato (es: qwen2.5-7b-instruct)
AGENT_MODEL=claude-sonnet-4-20250514

# Temperatura (0.0 = deterministico, 1.0 = creativo)
# Per SQL consigliato: 0.3
LLM_TEMPERATURE=0.3


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                   3. FAQ E RIASSUNTI (Modello Leggero)                        │
# └──────────────────────────────────────────────────────────────────────────────┘
# Provider per FAQ e riassunti conversazioni (può essere diverso dall'agent)
# Lascia commentato per usare lo stesso provider dell'agent
# Opzioni: anthropic | openai | gemini | lmstudio
FAQ_PROVIDER=lmstudio

# Modello per FAQ (se usi provider cloud)
# Consigliato un modello economico: claude-3-5-haiku-20241022, gpt-4o-mini
FAQ_MODEL=claude-3-5-haiku-20241022


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                    4. LM STUDIO (LLM Locale)                                  │
# └──────────────────────────────────────────────────────────────────────────────┘
# Configurazione per LM Studio (usato se LLM_PROVIDER=lmstudio o FAQ_PROVIDER=lmstudio)

# URL del server LM Studio (API OpenAI-compatibile)
LOCAL_LLM_URL=http://localhost:1234/v1/chat/completions

# Modello principale (per agent se LLM_PROVIDER=lmstudio)
# Consigliati: qwen2.5-7b-instruct, mistral-7b-instruct
LOCAL_LLM_MODEL=qwen2.5-7b-instruct

# Modello leggero (per FAQ e riassunti)
# Consigliati: qwen2-0.5b-instruct, phi-3-mini
LOCAL_LLM_LIGHT_MODEL=qwen2-0.5b-instruct


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                         5. API KEYS                                           │
# └──────────────────────────────────────────────────────────────────────────────┘
# Inserisci solo le API key dei provider che utilizzi

# Anthropic (Claude)
ANTHROPIC_API_KEY=sk-ant-your-key-here

# OpenAI (GPT) - opzionale
OPENAI_API_KEY=

# Google Gemini - opzionale
GEMINI_API_KEY=


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                         6. SICUREZZA                                          │
# └──────────────────────────────────────────────────────────────────────────────┘
# Chiave segreta per JWT (OBBLIGATORIA)
# Genera con: python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-minimum-32-chars

# Durata sessioni utente in ore
SESSION_EXPIRE_HOURS=24


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                         7. URLs (Docker)                                      │
# └──────────────────────────────────────────────────────────────────────────────┘
# URLs per comunicazione tra servizi Docker
BACKEND_URL=http://backend:8000
FRONTEND_URL=http://frontend:8501


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                         8. EMAIL (SMTP)                                       │
# └──────────────────────────────────────────────────────────────────────────────┘
# Configurazione per invio report schedulati via email
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USERNAME=your-smtp-username
SMTP_PASSWORD=your-smtp-password-here
SMTP_USE_SSL=true
SMTP_FROM_EMAIL=noreply@example.com


# ┌──────────────────────────────────────────────────────────────────────────────┐
# │                         9. DEBUG (Opzionale)                                  │
# └──────────────────────────────────────────────────────────────────────────────┘
# Abilita log dettagliati di input/output LLM (ATTENZIONE: log molto grandi!)
# ENABLE_LLM_TRACING=false
